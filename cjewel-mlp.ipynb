{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":115176,"databundleVersionId":13956865,"sourceType":"competition"},{"sourceId":12960498,"sourceType":"datasetVersion","datasetId":7439288}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2097.285466,"end_time":"2025-07-18T15:45:43.373134","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-18T15:10:46.087668","version":"2.6.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install git+https://github.com/cayleypy/cayleypy --quiet","metadata":{"execution":{"iopub.status.busy":"2025-10-26T06:30:19.401295Z","iopub.execute_input":"2025-10-26T06:30:19.401466Z","iopub.status.idle":"2025-10-26T06:31:44.657397Z","shell.execute_reply.started":"2025-10-26T06:30:19.401451Z","shell.execute_reply":"2025-10-26T06:31:44.656624Z"},"papermill":{"duration":10.529625,"end_time":"2025-07-18T15:11:01.087254","exception":false,"start_time":"2025-07-18T15:10:50.557629","status":"completed"},"tags":[],"ExecuteTime":{"end_time":"2025-08-29T19:20:53.393711Z","start_time":"2025-08-29T19:20:48.494352Z"},"id":"a9c0f644","outputId":"cd83936b-c7a7-4bff-abae-9ce90df39c26","trusted":true},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for cayleypy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:31:44.658254Z","iopub.execute_input":"2025-10-26T06:31:44.658456Z","iopub.status.idle":"2025-10-26T06:31:44.926391Z","shell.execute_reply.started":"2025-10-26T06:31:44.658433Z","shell.execute_reply":"2025-10-26T06:31:44.925875Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"INPUTS_DIR = Path(\"/kaggle/input/cayleypy-christophers-jewel\")\nwith open(INPUTS_DIR/\"puzzle_info.json\", \"r\") as file:\n    puzzle_info = json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:31:44.927696Z","iopub.execute_input":"2025-10-26T06:31:44.928109Z","iopub.status.idle":"2025-10-26T06:31:44.951541Z","shell.execute_reply.started":"2025-10-26T06:31:44.928091Z","shell.execute_reply":"2025-10-26T06:31:44.951072Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# a bunch of utility functions\n\ndef cyclic2oneline(cycle_str, n):\n    \"\"\"\n    Taken from\n    https://www.kaggle.com/code/olganikitina/permutations-cyclic-to-oneline/\n    \"\"\"\n    one_line = list(range(n))\n\n    cycles = cycle_str.replace(\" \", \"\").split(\")\")\n    for cycle in cycles:\n        if not cycle:\n            continue\n        cycle = cycle.replace(\"(\", \"\").split(\",\")\n        cycle = [int(x) - 1 for x in cycle]\n        for i in range(len(cycle) - 1):\n            one_line[cycle[i]] = cycle[i + 1]\n        one_line[cycle[-1]] = cycle[0]\n\n    return one_line\n\n\n\ndef inverse_permutation(perm):\n    \"\"\"\n    Inverts oneline permutation.Taken from:\n    https://www.kaggle.com/code/alexandervc/permutations-with-numpy-tutorial#Compute-inverse-permutation\n    \"\"\"\n    # Create an empty list to hold the inverse permutation\n    inverse = [0] * len(perm)\n\n    # Iterate over the original permutation\n    for i, p in enumerate(perm):\n        # Place the index at the correct position in the inverse permutation\n        inverse[p] = i\n\n    return inverse\n\n\ndef perm_is_id(perm):\n    return np.all(perm == np.arange(len(perm)))\n\n\ndef add_inv_permutations(perms_dict):\n    \"\"\"\n    Combining original and inverce permutations\n    WARNING: this functionm doesn't check if the inverted permutations are already present\n    \"\"\"\n    perms_dict_all = {}\n\n    for name, perm in perms_dict.items():\n        if not perm_is_id(perm):\n            perms_dict_all[name] = perm\n            perms_dict_all[name+\"_inv\"] = np.array(inverse_permutation(perm))\n    return perms_dict_all\n\ndef get_permuted_set_length(perms_cyclic):\n    \"\"\"\n    Takes the max id, the actual set length might be bigger, but why should it be?\n    \"\"\"\n    max_idx = 0\n    for p in perms_cyclic:\n        ids = [int(x) for x in p.strip(\"(\").strip(\")\").replace(\")(\",\",\").split(\",\")]\n        for idx in ids:\n           if idx > max_idx:\n               max_idx = idx\n    return max_idx\n\n\ndef moves_from_twizzle_explorer_to_dict(moves_list_gap):\n    return_dict = {}\n    for x in moves_list_gap:\n        kv = x.replace(\";\", \"\").split(\":=\")\n        return_dict[kv[0].replace(\"M_\",\"\")] = kv[1]\n    return return_dict\n\ndef filter_generator_lines(gap_str):\n    return [x for x in  gap_str.split(\"\\n\") if \":=\" in x and \"Gen\" not in x and \"ip\" not in x]\n\ndef write_json(path, obj):\n    with open(path, \"w+\") as file:\n        json.dump(obj, file, indent=4)\n\n\n","metadata":{"ExecuteTime":{"end_time":"2025-10-07T16:12:12.713875Z","start_time":"2025-10-07T16:12:12.698831Z"},"id":"914d758f282d287e","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:31:44.952228Z","iopub.execute_input":"2025-10-26T06:31:44.952398Z","iopub.status.idle":"2025-10-26T06:31:44.962477Z","shell.execute_reply.started":"2025-10-26T06:31:44.952383Z","shell.execute_reply":"2025-10-26T06:31:44.961738Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"central_state = np.array(puzzle_info[\"central_state\"])\ngenerators = {k: np.array(v) for k, v in puzzle_info[\"generators\"].items()}\nprint(f\"central_state: {central_state}\", end=\"\\n\\n\")\nprint(f\"Generator_names: {list(generators.keys())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:31:44.963235Z","iopub.execute_input":"2025-10-26T06:31:44.963478Z","iopub.status.idle":"2025-10-26T06:31:44.982822Z","shell.execute_reply.started":"2025-10-26T06:31:44.963455Z","shell.execute_reply":"2025-10-26T06:31:44.982259Z"}},"outputs":[{"name":"stdout","text":"central_state: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n\nGenerator_names: ['DBRRF', '-DBRRF', 'UBBBLL', '-UBBBLL', 'DFLBL', '-DFLBL', 'URBRBB', '-URBRBB', 'DBLBBBR', '-DBLBBBR', 'ULFR', '-ULFR']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from cayleypy import PermutationGroups, CayleyGraph, Predictor, prepare_graph, CayleyGraphDef\nimport numpy as np\nimport torch\n\npuzzle_name = \"Christopher's jewel\"\ngap_generators = \"# /home/username/.bun/bin/bun /home/username/Desktop/cayley/cubing.js/src/bin/puzzle-geometry-bin.ts --gap Christopher's jewel\\n# PuzzleGeometry 0.1 Copyright 2018 Tomas Rokicki.\\n# \\nM_DBRRF:=(5,8,11,18)(6,7,12,17)(33,36,35,34);\\nM_UBBBLL:=(13,24,21,20)(14,23,22,19)(41,44,43,42);\\nM_DFLBL:=(1,6,15,24)(2,5,16,23)(45,48,47,46);\\nM_URBRBB:=(3,20,9,12)(4,19,10,11)(29,32,31,30);\\nM_DBLBBBR:=(9,22,15,18)(10,21,16,17)(37,40,39,38);\\nM_ULFR:=(1,14,3,8)(2,13,4,7)(25,28,27,26);\\nGen:=[\\nM_DBRRF,M_UBBBLL,M_DFLBL,M_URBRBB,M_DBLBBBR,M_ULFR\\n];\\nip:=[[1],[3],[5],[7],[9],[11],[13],[15],[17],[19],[21],[23],[25],[29],[33],[37],[41],[45]];\\n# Size(Group(Gen));\\n# Size(Stabilizer(Group(Gen), ip, OnTuplesSets));\\n\"\ngens_names = list(generators.keys())\ngraph_def = CayleyGraphDef.create(\n    generators = [generators[x] for x in gens_names],\n    generator_names = gens_names,\n    central_state = central_state\n)\ngraph = CayleyGraph(graph_def, device='cuda')","metadata":{"execution":{"iopub.status.busy":"2025-10-26T06:31:44.983507Z","iopub.execute_input":"2025-10-26T06:31:44.983803Z","iopub.status.idle":"2025-10-26T06:31:52.247092Z","shell.execute_reply.started":"2025-10-26T06:31:44.983776Z","shell.execute_reply":"2025-10-26T06:31:52.246186Z"},"papermill":{"duration":8.508106,"end_time":"2025-07-18T15:11:09.598369","exception":false,"start_time":"2025-07-18T15:11:01.090263","status":"completed"},"tags":[],"ExecuteTime":{"end_time":"2025-10-07T16:12:16.185588Z","start_time":"2025-10-07T16:12:16.154944Z"},"id":"e2c87e5b","outputId":"3f4e3b84-78df-4e1f-f84b-0d15d0cd7b8f","trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/cayleypy/cayley_graph.py:96: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n  self.permutations_torch = torch.tensor(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"X, y = graph.random_walks(width=10000, length=25, mode=\"bfs\")","metadata":{"ExecuteTime":{"end_time":"2025-10-07T16:12:24.795762Z","start_time":"2025-10-07T16:12:20.71673Z"},"id":"fc43b852976c569","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T06:31:52.247895Z","iopub.execute_input":"2025-10-26T06:31:52.248335Z","iopub.status.idle":"2025-10-26T06:31:52.993645Z","shell.execute_reply.started":"2025-10-26T06:31:52.248315Z","shell.execute_reply":"2025-10-26T06:31:52.992871Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Training parameters.\nhidden_dims = [128, 256, 64]\nlearning_rate = 0.001\ndropout_p = 0.25\n\nclass Net(torch.nn.Module):\n    def __init__(self, input_size, num_classes, hidden_dims):\n        super().__init__()\n        self.num_classes=num_classes\n\n        input_size = input_size * self.num_classes\n        layers = []\n        for hidden_dim in hidden_dims:\n            layers.append(torch.nn.Linear(input_size, hidden_dim))\n            layers.append(torch.nn.BatchNorm1d(hidden_dim))\n            layers.append(torch.nn.GELU())\n            layers.append(torch.nn.Dropout(dropout_p))  # Add dropout after activation\n            input_size = hidden_dim\n            \n        layers.append(torch.nn.Linear(input_size, 1))\n        self.layers = torch.nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = torch.nn.functional.one_hot(x.long(), num_classes=self.num_classes).float().flatten(start_dim=-2)\n        return self.layers(x.float()).squeeze(-1)","metadata":{"ExecuteTime":{"end_time":"2025-10-07T16:12:29.717628Z","start_time":"2025-10-07T16:12:29.712675Z"},"id":"a883d3b6a10c5ae4","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:02:08.930516Z","iopub.execute_input":"2025-10-26T07:02:08.930813Z","iopub.status.idle":"2025-10-26T07:02:08.937562Z","shell.execute_reply.started":"2025-10-26T07:02:08.930793Z","shell.execute_reply":"2025-10-26T07:02:08.936737Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"input_size = graph.definition.state_size\nnum_classes = int(max(graph.central_state))+1\nmodel = Net(input_size, num_classes, hidden_dims).to(graph.device)\n\n# Prepare training and validation datasets.\nval_ratio = 0.2\nbatch_size = 10000\ndataset = TensorDataset(X, y.float())\nval_size = int(len(dataset) * val_ratio)\ntrain_size = len(dataset)-val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size)\n\n# loss_fn = torch.nn.MSELoss()\n# Trying HuberLoss\nloss_fn = torch.nn.HuberLoss()\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n# Trying AdamW\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-2)\n# Scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n\n\ndef train_one_epoch():\n    model.train()\n    total_train_loss = 0\n    for xb, yb in train_loader:\n        pred = model(xb)\n        loss = loss_fn(pred, yb)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_train_loss += loss.item() * xb.size(0)\n\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            pred = model(xb)\n            loss = loss_fn(pred, yb)\n            total_val_loss += loss.item() * xb.size(0)\n\n    avg_train_loss = total_train_loss / train_size\n    avg_val_loss = total_val_loss / val_size\n    print(f\"Epoch {epoch[0]+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n    epoch[0] +=1\n    return epoch, avg_train_loss, avg_val_loss","metadata":{"papermill":{"duration":4.937442,"end_time":"2025-07-18T15:11:14.539068","exception":false,"start_time":"2025-07-18T15:11:09.601626","status":"completed"},"tags":[],"ExecuteTime":{"end_time":"2025-10-07T16:12:35.602749Z","start_time":"2025-10-07T16:12:34.712686Z"},"id":"12058a7f","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:02:13.216356Z","iopub.execute_input":"2025-10-26T07:02:13.216637Z","iopub.status.idle":"2025-10-26T07:02:13.439475Z","shell.execute_reply.started":"2025-10-26T07:02:13.216616Z","shell.execute_reply":"2025-10-26T07:02:13.438931Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"epoch = [0]\nfor _ in range(128):\n    ep, train, val = train_one_epoch()\n    scheduler.step(val)","metadata":{"execution":{"iopub.status.busy":"2025-10-26T07:02:15.762295Z","iopub.execute_input":"2025-10-26T07:02:15.762859Z","iopub.status.idle":"2025-10-26T07:08:07.284892Z","shell.execute_reply.started":"2025-10-26T07:02:15.762836Z","shell.execute_reply":"2025-10-26T07:08:07.284033Z"},"papermill":{"duration":291.628489,"end_time":"2025-07-18T15:16:06.170841","exception":false,"start_time":"2025-07-18T15:11:14.542352","status":"completed"},"tags":[],"ExecuteTime":{"end_time":"2025-10-07T16:15:03.076675Z","start_time":"2025-10-07T16:12:43.859227Z"},"id":"0cdd4f6f","outputId":"cb50aa1a-8c64-41e2-bd9d-ea53ff165f50","trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1 | Train Loss: 13.2128 | Val Loss: 13.2491\nEpoch 2 | Train Loss: 12.7541 | Val Loss: 12.8696\nEpoch 3 | Train Loss: 12.2974 | Val Loss: 11.7030\nEpoch 4 | Train Loss: 11.8008 | Val Loss: 10.7939\nEpoch 5 | Train Loss: 11.2527 | Val Loss: 10.3687\nEpoch 6 | Train Loss: 10.6623 | Val Loss: 10.0063\nEpoch 7 | Train Loss: 10.0129 | Val Loss: 9.5201\nEpoch 8 | Train Loss: 9.3012 | Val Loss: 8.8325\nEpoch 9 | Train Loss: 8.5172 | Val Loss: 8.0437\nEpoch 10 | Train Loss: 7.6660 | Val Loss: 7.1688\nEpoch 11 | Train Loss: 6.7636 | Val Loss: 6.2978\nEpoch 12 | Train Loss: 5.8538 | Val Loss: 5.4479\nEpoch 13 | Train Loss: 4.9672 | Val Loss: 4.5243\nEpoch 14 | Train Loss: 4.1234 | Val Loss: 3.5039\nEpoch 15 | Train Loss: 3.4548 | Val Loss: 3.0068\nEpoch 16 | Train Loss: 2.9935 | Val Loss: 2.6216\nEpoch 17 | Train Loss: 2.7111 | Val Loss: 2.3067\nEpoch 18 | Train Loss: 2.5503 | Val Loss: 2.1493\nEpoch 19 | Train Loss: 2.4565 | Val Loss: 2.0687\nEpoch 20 | Train Loss: 2.4045 | Val Loss: 2.0284\nEpoch 21 | Train Loss: 2.3613 | Val Loss: 2.0028\nEpoch 22 | Train Loss: 2.3369 | Val Loss: 1.9855\nEpoch 23 | Train Loss: 2.3144 | Val Loss: 1.9710\nEpoch 24 | Train Loss: 2.2846 | Val Loss: 1.9614\nEpoch 25 | Train Loss: 2.2648 | Val Loss: 1.9469\nEpoch 26 | Train Loss: 2.2457 | Val Loss: 1.9432\nEpoch 27 | Train Loss: 2.2327 | Val Loss: 1.9215\nEpoch 28 | Train Loss: 2.2205 | Val Loss: 1.9243\nEpoch 29 | Train Loss: 2.2087 | Val Loss: 1.9153\nEpoch 30 | Train Loss: 2.1921 | Val Loss: 1.9081\nEpoch 31 | Train Loss: 2.1828 | Val Loss: 1.8983\nEpoch 32 | Train Loss: 2.1776 | Val Loss: 1.8977\nEpoch 33 | Train Loss: 2.1766 | Val Loss: 1.8917\nEpoch 34 | Train Loss: 2.1505 | Val Loss: 1.8948\nEpoch 35 | Train Loss: 2.1424 | Val Loss: 1.8894\nEpoch 36 | Train Loss: 2.1384 | Val Loss: 1.8790\nEpoch 37 | Train Loss: 2.1311 | Val Loss: 1.8705\nEpoch 38 | Train Loss: 2.1203 | Val Loss: 1.8817\nEpoch 39 | Train Loss: 2.1152 | Val Loss: 1.8671\nEpoch 40 | Train Loss: 2.1082 | Val Loss: 1.8664\nEpoch 41 | Train Loss: 2.1043 | Val Loss: 1.8687\nEpoch 42 | Train Loss: 2.0903 | Val Loss: 1.8654\nEpoch 43 | Train Loss: 2.0878 | Val Loss: 1.8611\nEpoch 44 | Train Loss: 2.0824 | Val Loss: 1.8580\nEpoch 45 | Train Loss: 2.0689 | Val Loss: 1.8540\nEpoch 46 | Train Loss: 2.0705 | Val Loss: 1.8531\nEpoch 47 | Train Loss: 2.0638 | Val Loss: 1.8422\nEpoch 48 | Train Loss: 2.0551 | Val Loss: 1.8426\nEpoch 49 | Train Loss: 2.0489 | Val Loss: 1.8506\nEpoch 50 | Train Loss: 2.0485 | Val Loss: 1.8426\nEpoch 51 | Train Loss: 2.0392 | Val Loss: 1.8461\nEpoch 52 | Train Loss: 2.0416 | Val Loss: 1.8402\nEpoch 53 | Train Loss: 2.0341 | Val Loss: 1.8387\nEpoch 54 | Train Loss: 2.0306 | Val Loss: 1.8349\nEpoch 55 | Train Loss: 2.0199 | Val Loss: 1.8343\nEpoch 56 | Train Loss: 2.0160 | Val Loss: 1.8427\nEpoch 57 | Train Loss: 2.0088 | Val Loss: 1.8293\nEpoch 58 | Train Loss: 2.0033 | Val Loss: 1.8298\nEpoch 59 | Train Loss: 2.0031 | Val Loss: 1.8284\nEpoch 60 | Train Loss: 1.9970 | Val Loss: 1.8214\nEpoch 61 | Train Loss: 1.9867 | Val Loss: 1.8185\nEpoch 62 | Train Loss: 1.9893 | Val Loss: 1.8181\nEpoch 63 | Train Loss: 1.9870 | Val Loss: 1.8246\nEpoch 64 | Train Loss: 1.9798 | Val Loss: 1.8175\nEpoch 65 | Train Loss: 1.9788 | Val Loss: 1.8167\nEpoch 66 | Train Loss: 1.9724 | Val Loss: 1.8160\nEpoch 67 | Train Loss: 1.9675 | Val Loss: 1.8181\nEpoch 68 | Train Loss: 1.9692 | Val Loss: 1.8108\nEpoch 69 | Train Loss: 1.9597 | Val Loss: 1.8182\nEpoch 70 | Train Loss: 1.9613 | Val Loss: 1.8096\nEpoch 71 | Train Loss: 1.9632 | Val Loss: 1.8120\nEpoch 72 | Train Loss: 1.9467 | Val Loss: 1.8126\nEpoch 73 | Train Loss: 1.9504 | Val Loss: 1.8094\nEpoch 74 | Train Loss: 1.9464 | Val Loss: 1.8083\nEpoch 75 | Train Loss: 1.9442 | Val Loss: 1.8052\nEpoch 76 | Train Loss: 1.9445 | Val Loss: 1.8103\nEpoch 77 | Train Loss: 1.9352 | Val Loss: 1.8050\nEpoch 78 | Train Loss: 1.9358 | Val Loss: 1.8016\nEpoch 79 | Train Loss: 1.9344 | Val Loss: 1.8170\nEpoch 80 | Train Loss: 1.9294 | Val Loss: 1.8117\nEpoch 81 | Train Loss: 1.9331 | Val Loss: 1.8044\nEpoch 82 | Train Loss: 1.9343 | Val Loss: 1.8049\nEpoch 83 | Train Loss: 1.9221 | Val Loss: 1.8007\nEpoch 84 | Train Loss: 1.9238 | Val Loss: 1.8002\nEpoch 85 | Train Loss: 1.9181 | Val Loss: 1.7959\nEpoch 86 | Train Loss: 1.9174 | Val Loss: 1.7981\nEpoch 87 | Train Loss: 1.9143 | Val Loss: 1.7942\nEpoch 88 | Train Loss: 1.9191 | Val Loss: 1.7937\nEpoch 89 | Train Loss: 1.9076 | Val Loss: 1.8073\nEpoch 90 | Train Loss: 1.9054 | Val Loss: 1.8013\nEpoch 91 | Train Loss: 1.9051 | Val Loss: 1.7943\nEpoch 92 | Train Loss: 1.9060 | Val Loss: 1.7924\nEpoch 93 | Train Loss: 1.9036 | Val Loss: 1.7964\nEpoch 94 | Train Loss: 1.8956 | Val Loss: 1.7923\nEpoch 95 | Train Loss: 1.8997 | Val Loss: 1.7924\nEpoch 96 | Train Loss: 1.8890 | Val Loss: 1.7961\nEpoch 97 | Train Loss: 1.8946 | Val Loss: 1.7980\nEpoch 98 | Train Loss: 1.8897 | Val Loss: 1.7927\nEpoch 99 | Train Loss: 1.8781 | Val Loss: 1.7918\nEpoch 100 | Train Loss: 1.8754 | Val Loss: 1.7873\nEpoch 101 | Train Loss: 1.8737 | Val Loss: 1.7874\nEpoch 102 | Train Loss: 1.8766 | Val Loss: 1.7828\nEpoch 103 | Train Loss: 1.8733 | Val Loss: 1.7846\nEpoch 104 | Train Loss: 1.8692 | Val Loss: 1.7846\nEpoch 105 | Train Loss: 1.8725 | Val Loss: 1.7833\nEpoch 106 | Train Loss: 1.8654 | Val Loss: 1.7805\nEpoch 107 | Train Loss: 1.8697 | Val Loss: 1.7790\nEpoch 108 | Train Loss: 1.8604 | Val Loss: 1.7803\nEpoch 109 | Train Loss: 1.8600 | Val Loss: 1.7810\nEpoch 110 | Train Loss: 1.8552 | Val Loss: 1.7848\nEpoch 111 | Train Loss: 1.8612 | Val Loss: 1.7770\nEpoch 112 | Train Loss: 1.8544 | Val Loss: 1.7802\nEpoch 113 | Train Loss: 1.8616 | Val Loss: 1.7762\nEpoch 114 | Train Loss: 1.8619 | Val Loss: 1.7822\nEpoch 115 | Train Loss: 1.8632 | Val Loss: 1.7800\nEpoch 116 | Train Loss: 1.8514 | Val Loss: 1.7808\nEpoch 117 | Train Loss: 1.8585 | Val Loss: 1.7810\nEpoch 118 | Train Loss: 1.8521 | Val Loss: 1.7817\nEpoch 119 | Train Loss: 1.8574 | Val Loss: 1.7775\nEpoch 120 | Train Loss: 1.8491 | Val Loss: 1.7778\nEpoch 121 | Train Loss: 1.8534 | Val Loss: 1.7767\nEpoch 122 | Train Loss: 1.8455 | Val Loss: 1.7781\nEpoch 123 | Train Loss: 1.8486 | Val Loss: 1.7765\nEpoch 124 | Train Loss: 1.8440 | Val Loss: 1.7743\nEpoch 125 | Train Loss: 1.8471 | Val Loss: 1.7767\nEpoch 126 | Train Loss: 1.8399 | Val Loss: 1.7753\nEpoch 127 | Train Loss: 1.8431 | Val Loss: 1.7727\nEpoch 128 | Train Loss: 1.8364 | Val Loss: 1.7752\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"torch.save(model, 'jewel_model_full.pth')","metadata":{"ExecuteTime":{"end_time":"2025-08-29T22:12:32.464778Z","start_time":"2025-08-29T22:12:31.958642Z"},"id":"17fd7b0bdf90f727","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:08:30.706463Z","iopub.execute_input":"2025-10-26T07:08:30.707286Z","iopub.status.idle":"2025-10-26T07:08:30.716554Z","shell.execute_reply.started":"2025-10-26T07:08:30.707260Z","shell.execute_reply":"2025-10-26T07:08:30.715762Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"test_df = pd.read_csv(INPUTS_DIR/\"test.csv\")\nX_test = test_df['initial_state'].apply(lambda x: [int(i) for i in x.split(',')]).tolist()\nX_test = torch.tensor(X_test)","metadata":{"id":"8d81cedb","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:08:32.804690Z","iopub.execute_input":"2025-10-26T07:08:32.805277Z","iopub.status.idle":"2025-10-26T07:08:32.858246Z","shell.execute_reply.started":"2025-10-26T07:08:32.805254Z","shell.execute_reply":"2025-10-26T07:08:32.857541Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"beam_size = 2**14\nmax_steps = 50","metadata":{"id":"ba5da612","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:08:36.377638Z","iopub.execute_input":"2025-10-26T07:08:36.378382Z","iopub.status.idle":"2025-10-26T07:08:36.381567Z","shell.execute_reply.started":"2025-10-26T07:08:36.378357Z","shell.execute_reply":"2025-10-26T07:08:36.380962Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport statistics as stat\n\ngraph.verbose = 1\nall_predicted_moves = []\n\nbar = tqdm(range(len(X_test)), desc=\"Processing instances\")\nfor i in bar:\n    predicted_moves = graph.beam_search(\n        start_state=X_test[i],\n        beam_width=beam_size,\n        predictor=Predictor(graph, model),\n        max_steps=max_steps,\n        return_path=True\n    )\n    all_predicted_moves.append(predicted_moves)\n    mean = round(stat.mean([item.path_length for item in all_predicted_moves]),2)\n    # Output solution length using tqdm.write\n    solution_length = predicted_moves.path_length if predicted_moves.path_length is not None else 0\n    bar.set_description(f\"L = {solution_length} | M = {mean}\", refresh=True)\n    # tqdm.write(f\"Instance {i}: Solution length = {solution_length}\")","metadata":{"id":"vf4YGofQv6O5","outputId":"5ccd3072-56f9-4466-8898-9b8eb9a48933","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:08:38.482879Z","iopub.execute_input":"2025-10-26T07:08:38.483152Z","iopub.status.idle":"2025-10-26T07:48:11.522819Z","shell.execute_reply.started":"2025-10-26T07:08:38.483131Z","shell.execute_reply":"2025-10-26T07:48:11.521831Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing instances:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bae48c9f9324992841e7eb6ebff4c5f"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def parse_initial_state(inital_state_str: str) -> np.ndarray:\n    return np.array([int(x) for x in inital_state_str.split(\",\")])\n\ndef parse_path(path_str: str) -> list[str]:\n    return list(path_str.split(\".\"))\n\ndf_sample_submission = pd.read_csv(INPUTS_DIR/\"sample_submission.csv\", index_col = \"initial_state_id\")\nfinal_paths = []\nfor i in range(1000):\n    sample_submission_path = df_sample_submission.loc[i][\"path\"]\n    sample_submission_path = parse_path(sample_submission_path)\n\n    beam_search_result = all_predicted_moves[i]\n    len_sample = len(sample_submission_path)\n    if beam_search_result.path_found:\n        len_bs = len(beam_search_result.path)\n        bs_success_str = \"True \"\n    else:\n        len_bs = np.inf\n        bs_success_str = \"False\"\n\n    if  len_sample < len_bs:\n        final_paths.append(\".\".join(sample_submission_path))\n    else:\n        final_paths.append(beam_search_result.get_path_as_string())","metadata":{"id":"PbeOTgAWbw_3","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:50:26.433315Z","iopub.execute_input":"2025-10-26T07:50:26.433583Z","iopub.status.idle":"2025-10-26T07:50:26.638615Z","shell.execute_reply.started":"2025-10-26T07:50:26.433564Z","shell.execute_reply":"2025-10-26T07:50:26.638106Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"final_paths[:10]","metadata":{"id":"dZC56kW0ddHQ","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:50:28.577209Z","iopub.execute_input":"2025-10-26T07:50:28.577474Z","iopub.status.idle":"2025-10-26T07:50:28.582920Z","shell.execute_reply.started":"2025-10-26T07:50:28.577454Z","shell.execute_reply":"2025-10-26T07:50:28.582132Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['DBLBBBR',\n '-UBBBLL.-ULFR',\n '-DBLBBBR',\n '-UBBBLL.-ULFR.DFLBL.-DBLBBBR',\n 'URBRBB.ULFR.-UBBBLL.-DBLBBBR.URBRBB',\n 'UBBBLL.-DBRRF',\n '-DFLBL.UBBBLL.-DFLBL.-DBLBBBR.UBBBLL.DFLBL.-DBRRF',\n '-DFLBL.-ULFR.DBRRF.DFLBL.-ULFR.DBLBBBR',\n 'UBBBLL.UBBBLL.-ULFR.DBRRF.URBRBB.DFLBL.-DBLBBBR.DBRRF.DBLBBBR',\n 'DFLBL.DFLBL.DBLBBBR.-UBBBLL.ULFR.ULFR']"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df = pd.DataFrame({\n    \"initial_state_id\": range(len(final_paths)),\n    \"path\": final_paths\n})\n\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T07:50:30.551150Z","iopub.execute_input":"2025-10-26T07:50:30.551833Z","iopub.status.idle":"2025-10-26T07:50:30.567779Z","shell.execute_reply.started":"2025-10-26T07:50:30.551811Z","shell.execute_reply":"2025-10-26T07:50:30.567166Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}